{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "NLP Disaster Tweets Analysis\n\nWeek 4 Assignment",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\nfrom keras.layers import Dense, LSTM, Embedding, Bidirectional, Dropout\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Introduction: \nThe first steps within this analysis will involve reading the data into the python script from the files online. After loading the files, we'll be able to dig in and explore the data and what it's architecture looks like more.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Load Dataset\ndataset = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n\nsentences = dataset['text']\ntarget = dataset['target']\ntarget = np.array(target)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "EDA:\n\nWe have both test and train datasets. They both contain five different columns: ID, Keyword (a keyword from that tweets_, Location (the location the tweet was sent from), test (the text of the tweet), and the target (1 if the tweet is a real disaster and 0 if it is not). \n\nBased on the code below, we know that the breakdown of the architecture of the data looks like this:\n\nTraining Set Shape = (7613, 5)\nTraining Set Memory Usage = 0.29 MB\nTest Set Shape = (3263, 4)\nTest Set Memory Usage = 0.10 MB\n\nAdditionally, here are some breakdown metrics of the data:\n\nTrain Length Stat\ncount    7613.000000;\nmean      101.037436;\nstd        33.781325;\nmin         7.000000;\n25%        78.000000;\n50%       107.000000;\n75%       133.000000;\nmax       157.000000;\n\nName: length, dtype: float64\n\nTest Length Stat\ncount    3263.000000;\nmean      102.108183;\nstd        33.972158;\nmin         5.000000;\n25%        78.000000;\n50%       109.000000;\n75%       134.000000;\nmax       151.000000;\n\nName: length, dtype: float64",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print('Training Set Shape = {}'.format(dataset.shape))\nprint('Training Set Memory Usage = {:.2f} MB'.format(dataset.memory_usage().sum() / 1024**2))\nprint('Test Set Shape = {}'.format(test.shape))\nprint('Test Set Memory Usage = {:.2f} MB'.format(test.memory_usage().sum() / 1024**2))\n\ndataset.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dataset[\"length\"] = dataset[\"text\"].apply(lambda x : len(x))\ntest[\"length\"] = test[\"text\"].apply(lambda x : len(x))\n\nprint(\"Train Length Stat\")\nprint(dataset[\"length\"].describe())\nprint()\n\nprint(\"Test Length Stat\")\nprint(test[\"length\"].describe())",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Tokenization\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(sentences)\nvocab_size = len(tokenizer.word_index) + 1\n\nencoded_text = tokenizer.texts_to_sequences(sentences)\npadded_text = pad_sequences(encoded_text, maxlen=65, padding='post')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Model Architecture: \n\nPlease see above for specific details on the dataset. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model = Sequential([\n    Embedding(vocab_size, 64, input_length=65),\n    Bidirectional(LSTM(64, return_sequences=True)),\n    Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.2)),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Learning Rate Schedule and Early Stopping\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Model Training\nx = padded_text\ny = target\n\nmodel.fit(x, y, epochs=10, batch_size=64, validation_split=0.2, callbacks=[reduce_lr, early_stopping])",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Test Data\ntest_sentences = test['text']\nencoded_test_text = tokenizer.texts_to_sequences(test_sentences)\npadded_test_text = pad_sequences(encoded_test_text, maxlen=65, padding='post')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Prediction\npredictions = model.predict(padded_test_text)\nbinary_pred = (predictions > 0.5).astype(int)\n\nids = test['id']",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Results and Analysis\n\nScore came out to be 0.654 on model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Save predictions to CSV file\nsubmission_df = pd.DataFrame({'id': ids, 'target': binary_pred.flatten()})\nsubmission_df.to_csv('submission.csv', index=False)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Conclusion\n\nAfter reviewing how this model and assignment went, there is definitley room for improvement. However, with that said, I was pleasently happy with how the model came out. I learned more about how to implament code like this, as to analyze writing/text.\n\nIn my next assignment, I would love to learn more about ways to tune the model to be more in tune with themes and sentiment from the texts. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}