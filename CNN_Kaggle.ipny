{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##Cancer Detecetion Report\n\nsample_df = pd.read_csv(\"/kaggle/input/histopathologic-cancer-detection/sample_submission.csv\")\nlabel_df = pd.read_csv(\"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\")\n\n#Read in Packages\nimport numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport time\nimport cv2\nfrom sklearn import metrics\nimport gc\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data**\n\nThere are 220025 training data records, and it takes about 30min to read all of them.\n\n\nThe original data is available in kaggle competition website.\n\nhttps://www.kaggle.com/competitions/histopathologic-cancer-detection/data\n","metadata":{}},{"cell_type":"code","source":"print(\"n of train data = \", label_df.shape[0])\nprint(\"n of test data  = \", sample_df.shape[0])\n\nfpath = \"/kaggle/input/cancerdetection-npy/X_test.npy\"\nX_test = np.load(fpath)\nfpath = \"/kaggle/input/cancerdetection-npy/X_val.npy\"\nX_val = np.load(fpath)\n\nfpath = \"/kaggle/input/cancerdetection-npy/y_val.npy\"\ny_val = np.load(fpath)\n\nfpath = \"/kaggle/input/cancerdetection-npy/X_train.npy\"\nX_train = np.load(fpath)[0:50000]\n\nfpath = \"/kaggle/input/cancerdetection-npy/y_train.npy\"\ny_train = np.load(fpath)[0:50000]\n\nX_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train = X_train.shape[0]\nn_test = X_test.shape[0]\nn_val = X_val.shape[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EDA**\n\n\nIn the original train data, 40% of labels are positive (cancer). To make training efficient, the train data is re-sampled to be 50% positive.","metadata":{}},{"cell_type":"code","source":"label_df[\"label\"].mean(), y_train.mean()\n\nfig, ax = plt.subplots(1, 2, figsize = (9, 3.5))\nax[0].hist(label_df[\"label\"])\nax[1].hist(y_train.flatten(), color = \"darkorange\")\nax[0].set_title(\"labels of original train data\")\nax[1].set_title(\"labels of train data (balanced sampling)\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Train and Test\n\nnp.random.seed(1)\nsample_train = np.random.choice(n_train, 5000)\nsample_test = np.random.choice(n_test, 5000)\n\nfig, ax = plt.subplots(1, 3, figsize = (12, 3))\n\ntitles = [\"R\", \"G\", \"B\"]\nfor i in range(3):\n    ax[i].hist(X_train[sample_train, :,:,i].flatten(), density = True, alpha = 0.7, bins = 20, label = \"train\")\n    ax[i].hist(X_test[sample_test, :,:,i].flatten(), density = True, alpha = 0.7, bins = 20, label = \"test\")\n    ax[i].set_title(titles[i])\n    ax[i].legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution Plots\n\nsample_pos = y_val.flatten() == 1\nsample_neg = y_val.flatten() == 0\n\nfig, ax = plt.subplots(1, 3, figsize = (12, 3))\n\ntitles = [\"R\", \"G\", \"B\"]\nfor i in range(3):\n    ax[i].hist(X_val[sample_neg, :,:,i].flatten(), density = True, alpha = 0.7, bins = 20, label = \"normal\")\n    ax[i].hist(X_val[sample_pos, :,:,i].flatten(), density = True, alpha = 0.7, bins = 20, label = \"cancer\")\n    ax[i].set_title(titles[i])\n    ax[i].legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Photo Plot\n\ndef plot_photo(X):\n    \n    N = X.shape[0]\n    nc = 10\n    nr = math.ceil(N/nc)\n    \n    fig, ax = plt.subplots(nr, nc, figsize = (14, nr*1.4))\n    \n    for k in range(N):\n        i =  int(k/nc)\n        j = k % nc\n        ax[i,j].imshow(X[k])\n        ax[i,j].tick_params(left = False, right = False , labelleft = False, labelbottom = False, bottom = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Non Cancer Plot\nplot_photo(X_val[sample_neg][0:80])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cancer Plot\nplot_photo(X_val[sample_pos][0:80])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prediction from RGB \n# Calculation of mean RGB\nZ_train = np.zeros((n_train, 3))\nZ_val = np.zeros((n_val, 3))\nZ_test = np.zeros((n_test, 3))\n\nfor j in range(3):\n\n    for i in range(n_train):\n        Z_train[i,j] = np.mean(X_train[i,:,:,j])\n\n    for i in range(n_val):\n        Z_val[i,j] = np.mean(X_val[i,:,:,j])\n\n    for i in range(n_test):\n        Z_test[i,j] = np.mean(X_test[i,:,:,j])\n        \nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(max_depth=10, random_state=0)\nclf.fit(Z_train, y_train.flatten())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VALIDATION AUC \nyhat_train = clf.predict_proba(Z_train)\nfpr, tpr, thresholds = metrics.roc_curve(y_train, yhat_train[:,1], pos_label=1)\ntrain_auc = metrics.auc(fpr, tpr)\n\nyhat_val = clf.predict_proba(Z_val)\nfpr, tpr, thresholds = metrics.roc_curve(y_val, yhat_val[:,1], pos_label=1)\nval_auc = metrics.auc(fpr, tpr)\n\nprint(\"train auc\", np.round(train_auc, 3))\nprint(\"validation auc\", np.round(val_auc, 3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#yhat_test = clf.predict_proba(Z_test)[:,1]\n#test_submit = sample_df.copy()\n#test_submit[\"label\"] = yhat_test\n#test_submit.to_csv('submission.csv',index=False)\ndel X_test\ngc.collect()\n\n#0.8151 Kaggle Score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Modeling/ Dmodel Architecture**","metadata":{}},{"cell_type":"markdown","source":"1 Model of CNN will show below:\n\nmodel1: 5 x (Conv MaxPool)\n\n\nModels contain rescale and randomflip layer as preprocessing image.\n\nRescaling layer\nRandomFlip layer\nAs I tried some filter sizes, size = 3 was most stable and performance was better (faster learning and good accuracy) than size 5 and 7. MaxPooling layer should be after one or two Conv layers. I have tried Conv with stride = 2 instead of MaxPooling, but MaxPool was more stable.\n\nConvolusion filter size = 3\nMaxPooling size = 2 stride = 2\nBatch size and learning rate are closely related. I tried batch size 32, 64, and 128. 128 with default learning rate was the best. Furthermore, 50% of dropout is widely used in kaggle, and I can agree. When drop out ratio is small ( < 0.4), effect is not enough. For these model with 50,000 train images, the best epoch seems to be about 8, but I set epoch = 12, to clearly show overfitting symptoms.\n\nbatch size = 128 with adam lr = 0.0001 (default)\n50% Dropout in Dense layer (except for model3)\nThe number of epoch is 12 for all three models, which is enough to check overfitting.","metadata":{}},{"cell_type":"code","source":"X_shape = X_train[0].shape\ntf.keras.utils.set_random_seed(\n    seed = 2\n)\n\nmodel1 = models.Sequential()\n\nNF =64\nFS = 3\n\nmodel1.add(layers.Rescaling(scale=1./127.5, offset=-1., input_shape = X_shape))\nmodel1.add(layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=1, input_shape = X_shape))\n\nmodel1.add(layers.Conv2D(NF, (FS,FS), activation = \"relu\", padding = \"same\", input_shape = X_shape))\nmodel1.add(layers.MaxPooling2D((2,2)))\n\n\nFS = 3\nNF = NF*2\nmodel1.add(layers.Conv2D(NF, (FS,FS), activation = \"relu\", padding = \"same\"))\nmodel1.add(layers.MaxPooling2D((2,2)))\n\n\nFS = 3\nNF = NF*2\nmodel1.add(layers.Conv2D(NF, (FS,FS), activation = \"relu\", padding = \"same\"))\nmodel1.add(layers.MaxPooling2D((2,2)))\n\n\nFS = 3\nNF = NF*2\nmodel1.add(layers.Conv2D(NF, (FS,FS), activation = \"relu\", padding = \"same\"))\nmodel1.add(layers.MaxPooling2D((2,2)))\n\nFS = 3\nNF = NF\nmodel1.add(layers.Conv2D(NF, (FS,FS), activation = \"relu\", padding = \"same\"))\nmodel1.add(layers.MaxPooling2D((2,2)))\n\nmodel1.add(layers.Flatten())\nmodel1.add(layers.Dropout(0.5, seed = 1))\nmodel1.add(layers.Dense(512*9, activation = \"relu\"))\n\nmodel1.add(layers.Dense(2))\n\nmodel1.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel1.compile(\n    optimizer = \"adam\",\n    loss=loss_fn, \n    metrics=['accuracy'] \n    )\nhistory1 = model1.fit(X_train, y_train, batch_size = 128, epochs = 12, validation_data = (X_val, y_val))\ngc.collect()\ntf.keras.backend.clear_session()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntf.keras.backend.clear_session()\ndef plot_scores(history):\n    \n    fig, ax = plt.subplots(1,2, figsize = (12, 5))\n    ax[0].plot(history.history[\"accuracy\"], label = \"train\")\n    ax[0].plot(history.history[\"val_accuracy\"], label = \"val\")\n    ax[0].set_xlabel(\"epochs\")\n    ax[0].set_ylabel(\"accuracy\")\n    ax[0].set_ylim([0.7,1])\n    ax[0].set_title(\"Accuracy\")\n    ax[0].legend()\n\n    ax[1].plot(history.history[\"loss\"], label = \"train\")\n    ax[1].plot(history.history[\"val_loss\"], label = \"val\")\n    ax[1].set_xlabel(\"epochs\")\n    ax[1].set_ylabel(\"loss\")\n    ax[1].set_ylim([0,1])\n    ax[1].set_title(\"Loss\")\n    ax[1].legend()\n    \n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_scores(history1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation\nyhat_val = model1.predict(X_val)\nyhat_val = tf.nn.softmax(yhat_val).numpy()[:,1]\n\nfpr, tpr, thresholds = metrics.roc_curve(y_val, yhat_val, pos_label=1)\nval_auc = metrics.auc(fpr, tpr)\nprint(\"val auc\", val_auc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_val(model):\n    \n    #original\n    yhat_test1 = model.predict(X_val)\n    yhat_test1 = tf.nn.softmax(yhat_test1).numpy()[:,1]\n    \n    gc.collect()\n    \n    #flipped\n    yhat_test2 = model.predict(X_val[:,::-1,::-1,:])\n    yhat_test2 = tf.nn.softmax(yhat_test2).numpy()[:,1]\n    \n    gc.collect()\n    \n    #flipped\n    yhat_test3 = model.predict(X_val[:,::-1,:,:])\n    yhat_test3 = tf.nn.softmax(yhat_test3).numpy()[:,1]\n    \n    gc.collect()\n    \n    #flipped\n    yhat_test4 = model.predict(X_val[:,:,::-1,:])\n    yhat_test4 = tf.nn.softmax(yhat_test4).numpy()[:,1]\n    \n    gc.collect()\n    \n    #average\n    yhat_test =  (yhat_test1 + yhat_test2 + yhat_test3 + yhat_test4)/4\n    \n    return yhat_test\nyhat_val = pred_val(model1)\nfpr, tpr, thresholds = metrics.roc_curve(y_val, yhat_val, pos_label=1)\nval_auc = metrics.auc(fpr, tpr)\nprint(\"val auc (ensembled)\", val_auc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results and Conclusion**\n\n\nmodel 1 (Conv&MaxPool) converged faster but it had obvious overfitting, and model 2 (Conv&Conv&MaxPool) mitigated overfitting (ommitted due to memory issues). Validation accuracy was also improved by additional conv layers.\n\n\nFlipping image and ensemble predictions is effective\n\nTo get higher auc, input image for testing is flipped horizontally and vertically. Thus, one image has four prediction and they are ensembled. yhat = mean(yhat1(original), yhat2(vertical flip), yhat3 (horizontal flip), yhat4 (horizontal and vertical flip)). Almost everytime, it improved auc. CNN can be visualized somehow.\n\nIt is difficult to figure out which cells are cancers for non-professional persons. However, some technique of CNN can assist diagnosis. By cropping a part of image, and check probability of cancer by CNN, we can guess what are cancer cells look like.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}